import argparse
import logging
import os
import sys
import json
import re
from typing import List, Optional, TypedDict, Dict

from langgraph.graph import StateGraph, END
from langchain_core.language_models.chat_models import BaseChatModel
from pydantic import BaseModel, Field
from langchain.output_parsers import PydanticOutputParser
from langchain_core.output_parsers.string import StrOutputParser
from langchain.schema import OutputParserException
from langchain_core.prompts import ChatPromptTemplate

# --- Import des modules du projet ---
import config
from document_processor import process_all_journals
from vector_database import VectorDBManager
from llm_interface import get_configured_llm
from data_models import ReportPlan
from agent_tools import SectionStatusInput as Section
from agent_tools import GetPendingSectionsTool, UpdateSectionStatusTool
from report_planner import ReportPlanner
from reference_manager import ReferenceManager # Non utilis√© activement pour l'instant
from memory_manager import MemoryManager

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - [%(name)s] - %(message)s' # Nom du logger inclus
)
log = logging.getLogger(__name__)

# --- Sch√©ma Pydantic pour l'Analyse Holistique (inchang√©) ---
class ProjetCle(BaseModel):
    nom: str = Field(description="Nom concis du projet ou de la mission principale.")
    description_courte: str = Field(description="Tr√®s br√®ve description (1 phrase) du projet.")
    periode_activite: str = Field(description="P√©riode approximative (ex: 'Mars 2024 - Mai 2024', 'Q2 2025').")
    themes_associes: List[str] = Field(description="Liste des th√®mes ou mots-cl√©s principaux associ√©s (ex: 'Automatisation', 'IA G√©n√©rative', 'Gestion de projet').")

class Competence(BaseModel):
    nom_competence: str = Field(description="Nom de la comp√©tence technique, organisationnelle ou interpersonnelle acquise ou renforc√©e.")
    contexte_developpement: str = Field(description="Contexte sp√©cifique (projet, t√¢che) o√π la comp√©tence a √©t√© d√©velopp√©e.")
    type: str = Field(description="Type de comp√©tence (ex: 'Technique', 'Organisationnelle', 'Relationnelle').")

class ApprentissageCle(BaseModel):
    nom_apprentissage: str = Field(description="Titre concis de l'apprentissage cl√© ou de la prise de conscience.")
    description: str = Field(description="Br√®ve description de l'apprentissage.")
    contexte: str = Field(description="Contexte (projet, situation) ayant men√© √† cet apprentissage.")

class HolisticAnalysis(BaseModel):
    projets_cles: List[ProjetCle] = Field(description="Liste des projets ou missions les plus significatifs mentionn√©s dans les journaux.")
    competences_acquises_renforcees: List[Competence] = Field(description="Liste des comp√©tences cl√©s acquises ou significativement renforc√©es.")
    defis_majeurs: List[str] = Field(description="Liste des d√©fis ou difficult√©s majeures rencontr√©es.")
    apprentissages_cles: List[ApprentissageCle] = Field(description="Liste des apprentissages les plus importants tir√©s des exp√©riences.")
    fil_conducteur_narratif: str = Field(description="Proposition d'un fil conducteur ou d'une trame narrative pour le rapport, bas√©e sur l'ensemble des journaux.")

# --- √âtat du workflow LangGraph (Mis √† jour) ---
class ReportWorkflowState(TypedDict):
    objective: str
    current_section_id: Optional[str]
    current_section_title: Optional[str]
    structured_guidelines: List[str]
    journal_context: Optional[str]
    is_context_relevant: Optional[bool] # Indicateur de pertinence du contexte RAG
    analysis_result: Optional[str] # Plan structur√© pour la section
    written_content: Optional[str] # Prose r√©dig√©e pour la section
    is_prose_adequate: Optional[bool] # Indicateur de qualit√© de la prose
    prose_feedback: Optional[str]   # Feedback si la prose n'est pas ad√©quate
    final_content: Optional[str]   # Contenu final (apr√®s garde-fous)
    pending_check_result: str
    iterations: int
    writing_attempts: int # Compteur de tentatives pour la r√©daction d'une section
    error_message: Optional[str]

# --- Profil Utilisateur (inchang√©) ---
USER_PROFILE = """
üéì Profil ‚Äì √âtudiant en Master IA & Transformation d‚ÄôEntreprise | AI Project Officer chez Gecina
... (Profil complet) ...
Communication, vulgarisation et strat√©gie IA en entreprise
"""

# --- Analyse holistique des journaux (inchang√©e depuis la version pr√©c√©dente) ---
def run_holistic_analysis(llm: BaseChatModel, journal_dir: str, output_file: str):
    log.info("--- D√©marrage de l'Analyse Holistique des Journaux ---")
    raw_output_file = output_file.replace(".json", "_raw.txt") # Pour sauvegarde brute si erreur

    try:
        entries = process_all_journals(journal_dir)
        if not entries:
            log.error("Aucun journal trouv√©.")
            print("ERREUR: Aucun journal trouv√©.")
            return
        text = "\n\n".join([
            f"Entr√©e du {e.date.strftime('%Y-%m-%d')}:\n{e.raw_text}" for e in entries
        ])
        max_chars = config.HOLISTIC_ANALYSIS_MAX_CHARS
        if len(text) > max_chars:
            log.warning(f"Troncation du texte des journaux √† {max_chars} caract√®res pour l'analyse holistique.")
            text = text[:max_chars]
    except Exception as e:
        log.error(f"Erreur lors du chargement ou traitement des journaux: {e}", exc_info=True)
        print(f"ERREUR: Impossible de charger les journaux: {e}")
        return

    parser = PydanticOutputParser(pydantic_object=HolisticAnalysis)
    format_instructions = parser.get_format_instructions()

    prompt = f"""System: Tu es un extracteur de donn√©es JSON expert. Analyse le corpus de journaux fourni et extrais les informations cl√©s demand√©es. R√©ponds *uniquement* avec l'objet JSON valide demand√©, sans aucun texte additionnel, commentaire, ou explication avant ou apr√®s le JSON.

User:
**ROLE IA:** Analyste strat√©gique expert dans la r√©daction de m√©moires Epitech bas√©s sur des journaux de bord d'alternance.
**CONTEXTE AUTEUR:**
{USER_PROFILE}

**CORPUS DE JOURNAUX DE BORD:**
--- DEBUT JOURNAUX ---
{text}
--- FIN JOURNAUX ---

**TACHE:** Analyse l'int√©gralit√© du corpus de journaux ci-dessus. Identifie les projets cl√©s, les comp√©tences d√©velopp√©es, les d√©fis majeurs, les apprentissages principaux et propose un fil conducteur pour un rapport d'alternance. Structure ta r√©ponse **UNIQUEMENT** en JSON valide, en respectant strictement le format d√©crit ci-dessous. Ne fournis rien d'autre que l'objet JSON.

**FORMAT JSON ATTENDU (Instructions Pydantic):**
{format_instructions}

**R√àGLES STRICTES:**
1.  **Analyse Globale:** Base-toi sur l'ensemble des entr√©es fournies.
2.  **Synth√®se:** Sois concis et pertinent pour un rapport d'alternance.
3.  **Neutralit√©:** Rapporte les faits objectivement tels que d√©crits dans les journaux.
4.  **Anonymisation:** Utilise des r√¥les g√©n√©riques (ex: "le Manager", "l'√©quipe technique") si des noms sp√©cifiques apparaissent, conform√©ment au mapping de `config.py` si disponible (le mapping n'est pas fourni ici, fais au mieux).
5.  **Format JSON Strict:** La sortie doit √™tre *uniquement* l'objet JSON, sans aucun autre texte.

**JSON R√âSULTAT DE L'ANALYSE HOLISTIQUE:**
"""

    try:
        log.info("Invocation du LLM pour l'analyse holistique...")
        resp = llm.invoke(prompt)
        content = getattr(resp, 'content', '')

        if not content.strip():
            log.error("La r√©ponse du LLM pour l'analyse holistique est vide.")
            print("ERREUR: La r√©ponse du LLM est vide.")
            return

        log.info("Tentative de parsing de la r√©ponse LLM avec PydanticOutputParser...")
        with open(raw_output_file, 'w', encoding='utf-8') as f_raw:
            f_raw.write(content)
        log.info(f"R√©ponse brute du LLM sauvegard√©e dans: {raw_output_file}")

        try:
            parsed_data: HolisticAnalysis = parser.parse(content)
            with open(output_file, 'w', encoding='utf-8') as f_json:
                if hasattr(parsed_data, 'model_dump_json'):
                     f_json.write(parsed_data.model_dump_json(indent=4))
                else:
                     f_json.write(parsed_data.json(indent=4, ensure_ascii=False))
            log.info(f"Analyse holistique pars√©e et sauvegard√©e avec succ√®s: {output_file}")
            print(f"\nAnalyse holistique sauvegard√©e avec succ√®s: {output_file}\nV√©rifiez son contenu.")

        except OutputParserException as e_parse:
            log.error(f"√âchec du parsing JSON par PydanticOutputParser: {e_parse}", exc_info=True)
            log.warning("Tentative d'extraction manuelle du JSON...")
            json_match = re.search(r'```json\s*(\{.*?\})\s*```|(\{.*?\})', content, re.DOTALL)
            if json_match:
                json_str = json_match.group(1) or json_match.group(2)
                if json_str:
                    log.info("JSON potentiel extrait manuellement, nouvelle tentative de parsing...")
                    try:
                        parsed_data: HolisticAnalysis = parser.parse(json_str.strip())
                        with open(output_file, 'w', encoding='utf-8') as f_json:
                             if hasattr(parsed_data, 'model_dump_json'):
                                 f_json.write(parsed_data.model_dump_json(indent=4))
                             else:
                                 f_json.write(parsed_data.json(indent=4, ensure_ascii=False))
                        log.info(f"Analyse holistique extraite manuellement, pars√©e et sauvegard√©e: {output_file}")
                        print(f"\nAnalyse holistique sauvegard√©e (apr√®s extraction manuelle): {output_file}\nV√©rifiez son contenu.")
                    except (OutputParserException, json.JSONDecodeError) as e_reparse:
                         log.critical(f"√âchec du parsing m√™me apr√®s extraction manuelle: {e_reparse}")
                         print(f"ERREUR CRITIQUE: Impossible de parser le JSON de l'analyse holistique. V√©rifiez {raw_output_file}")
                else:
                     log.critical("Impossible d'extraire manuellement un bloc JSON valide.")
                     print(f"ERREUR CRITIQUE: Impossible d'extraire le JSON de l'analyse holistique. V√©rifiez {raw_output_file}")
            else:
                 log.critical("Aucun bloc JSON identifiable dans la r√©ponse LLM.")
                 print(f"ERREUR CRITIQUE: Aucun JSON trouv√© dans l'analyse holistique. V√©rifiez {raw_output_file}")

    except Exception as e_llm:
        log.error(f"Erreur g√©n√©rale durant l'analyse holistique (appel LLM ou autre): {e_llm}", exc_info=True)
        print(f"ERREUR: Une erreur s'est produite lors de l'analyse holistique: {e_llm}")
        if 'content' in locals() and content:
             with open(raw_output_file, 'w', encoding='utf-8') as f_raw_err:
                 f_raw_err.write(content)
             log.info(f"Contenu brut en erreur sauvegard√© : {raw_output_file}")

# --- Variables globales pour les composants partag√©s ---
llm_analysis: Optional[BaseChatModel] = None
llm_writing: Optional[BaseChatModel] = None
vector_db_manager: Optional[VectorDBManager] = None
memory_manager: Optional[MemoryManager] = None
holistic_analysis_content: Optional[Dict] = None # Charg√© une fois au d√©but de run_agent

# --- Point d'entr√©e ---
def main():
    global llm_analysis, llm_writing, vector_db_manager, memory_manager, holistic_analysis_content # D√©clare utiliser les globales

    parser = argparse.ArgumentParser(description="Agent IA pour la r√©daction de m√©moire Epitech")
    parser.add_argument("--llm", choices=config.LLM_PROVIDERS, default=None,
                        help="Force l'utilisation d'un fournisseur LLM sp√©cifique (ignore config.py).")
    sub = parser.add_subparsers(dest="command", required=True, help="Commande √† ex√©cuter")

    # --- D√©finition des commandes ---
    parser_analyze = sub.add_parser("analyze_journals", help="Effectue l'analyse holistique des journaux.")
    parser_analyze.add_argument("--journal_dir", default=config.JOURNAL_DIR, help="R√©pertoire contenant les fichiers journaux DOCX.")
    parser_analyze.add_argument("--output_file", default=config.HOLISTIC_ANALYSIS_FILE, help="Fichier JSON de sortie pour l'analyse.")

    parser_plan = sub.add_parser("create_plan", help="Cr√©e le plan initial du rapport (structure et statuts).")
    parser_plan.add_argument("--output_plan_file", default=config.DEFAULT_PLAN_FILE, help="Fichier JSON de sortie pour le plan.")

    parser_assemble = sub.add_parser("assemble_report", help="Assemble le rapport DOCX final depuis un plan JSON compl√©t√©.")
    parser_assemble.add_argument("--plan_file", default=config.DEFAULT_PLAN_FILE, help="Chemin vers le fichier plan JSON (avec contenu).")
    parser_assemble.add_argument("--output_file", default=config.DEFAULT_REPORT_OUTPUT, help="Chemin pour sauvegarder le rapport DOCX assembl√©.")

    parser_agent = sub.add_parser("run_agent", help="Lance le workflow de r√©daction section par section.")
    parser_agent.add_argument("--max_iterations", type=int, default=50, help="Nombre maximum de sections √† traiter.")
    parser_agent.add_argument("--max_writing_attempts", type=int, default=3, help="Nombre maximum de tentatives de r√©√©criture pour une section.")
    parser_agent.add_argument("--objective", default="G√©n√©rer un premier brouillon du rapport d'alternance.", help="Objectif global pour l'agent.")
    parser_agent.add_argument("--plan_file", default=config.DEFAULT_PLAN_FILE, help="Chemin vers le fichier plan JSON √† utiliser/mettre √† jour.")

    args = parser.parse_args()
    provider = args.llm or config.LLM_PROVIDER
    log.info(f"Utilisation du fournisseur LLM : {provider}")

    # --- Initialisation bas√©e sur la commande ---
    if args.command == "analyze_journals":
        llm_analysis = get_configured_llm(provider=provider, purpose="analysis")
        if not llm_analysis: sys.exit(1)
        run_holistic_analysis(llm_analysis, args.journal_dir, args.output_file)

    elif args.command == "create_plan":
        log.info("--- Commande: create_plan ---")
        # Utilisation de ReportPlanner ici
        planner = ReportPlanner()
        report_plan = planner.create_base_plan()
        # Utilisation de MemoryManager pour sauvegarder
        temp_memory = MemoryManager(plan_file=args.output_plan_file) # Instance temporaire juste pour sauver
        temp_memory.save_report_plan(report_plan, args.output_plan_file)
        log.info(f"Plan initial sauvegard√© : {args.output_plan_file}")
        print(f"\nPlan initial sauvegard√© : {args.output_plan_file}")

    elif args.command == "assemble_report":
        log.info("--- Commande: assemble_report ---")
        try:
            from report_generator import assemble_report_from_plan
            assemble_report_from_plan(args.plan_file, args.output_file)
            log.info(f"Rapport assembl√© avec succ√®s: {args.output_file}")
            print(f"\nRapport assembl√© et sauvegard√© : {args.output_file}")
        except ImportError:
             log.critical("Importation √©chou√©e pour 'report_generator.assemble_report_from_plan'.")
             sys.exit(1)
        except FileNotFoundError:
             log.error(f"Fichier plan '{args.plan_file}' non trouv√©.")
             sys.exit(1)
        except Exception as e_ass:
            log.error(f"Erreur assemblage: {e_ass}", exc_info=True)
            sys.exit(1)

    elif args.command == "run_agent":
        log.info(f"--- Commande: run_agent (Workflow Principal avec R√©flexion) ---")
        log.info(f"Utilisation du fichier plan : {args.plan_file}")

        # --- V√©rifications et Initialisation pour run_agent ---
        if not os.path.exists(config.HOLISTIC_ANALYSIS_FILE):
            print(f"ERREUR: Fichier analyse holistique '{config.HOLISTIC_ANALYSIS_FILE}' manquant. Lancez 'analyze_journals'.")
            sys.exit(1)
        if not os.path.exists(args.plan_file):
             print(f"ERREUR: Fichier plan '{args.plan_file}' manquant. Lancez 'create_plan'.")
             sys.exit(1)

        try:
            with open(config.HOLISTIC_ANALYSIS_FILE, 'r', encoding='utf-8') as f:
                holistic_analysis_content = json.load(f) # Chargement dans la variable globale
            log.info("Analyse holistique charg√©e.")

            # Initialisation des composants globaux
            vector_db_manager = VectorDBManager()
            memory_manager = MemoryManager(plan_file=args.plan_file)
            llm_analysis = get_configured_llm(provider=provider, purpose="analysis")
            llm_writing = get_configured_llm(provider=provider, purpose="writing")

            if not all([vector_db_manager, memory_manager, llm_analysis, llm_writing]):
                print("ERREUR: √âchec initialisation d'un ou plusieurs composants (DB, Mem, LLMs).")
                sys.exit(1)

            # V√©rification DB Vecteurs (optionnel: vectoriser si vide)
            if vector_db_manager.collection is None or vector_db_manager.collection.count() == 0:
                 log.warning("Base vectorielle vide. Contexte RAG limit√©.")
                 # print("AVERTISSEMENT: Base vectorielle vide...")

        except Exception as e_init:
            print(f"ERREUR critique lors de l'initialisation: {e_init}")
            log.critical(f"Erreur initialisation: {e_init}", exc_info=True)
            sys.exit(1)

        # --- D√©finition des outils et n≈ìuds du graphe ---
        get_pending = GetPendingSectionsTool(memory_manager=memory_manager)
        update_status = UpdateSectionStatusTool(memory_manager=memory_manager)

        def get_title_from_plan(plan: ReportPlan, sid: str) -> Optional[str]:
            # Fonction utilitaire (inchang√©e)
            if not plan or not plan.structure: return None
            queue: List[Section] = list(plan.structure)
            while queue:
                s = queue.pop(0)
                if getattr(s, 'section_id', None) == sid: return getattr(s, 'title', None)
                queue.extend(getattr(s, 'subsections', []))
            return None

        # --- N≈ìuds du workflow LangGraph (avec logique r√©elle) ---

        def check_pending(state: ReportWorkflowState) -> ReportWorkflowState:
            # (Logique inchang√©e par rapport √† la version pr√©c√©dente)
            log.info(f"Iteration {state.get('iterations', 0) + 1}. V√©rification sections...")
            result = get_pending.invoke({})
            log.info(f"R√©sultat check_pending: {result}")
            section_id = None if 'COMPLETED' in result or 'Erreur' in result else result
            error_msg = result if 'Erreur' in result else None
            return {
                **state,
                'pending_check_result': result,
                'current_section_id': section_id,
                'iterations': state.get('iterations', 0) + 1,
                'error_message': error_msg,
                'current_section_title': None, 'structured_guidelines': [], 'journal_context': None,
                'is_context_relevant': None, 'analysis_result': None, 'written_content': None,
                'is_prose_adequate': None, 'prose_feedback': None, 'final_content': None,
                'writing_attempts': 0, # R√©initialise compteur tentatives √©criture
            }

        def prepare_drafting(state: ReportWorkflowState) -> ReportWorkflowState:
            # (Logique inchang√©e par rapport √† la version pr√©c√©dente)
            sid = state['current_section_id']
            if not sid:
                log.error("ID section manquant (prepare_drafting).")
                return {**state, 'error_message': 'ID section manquant (prepare).'}
            log.info(f"Pr√©paration pour la section ID: {sid}")
            update_result = update_status.invoke({'tool_input': f"{sid},drafting"})
            log.info(f"R√©sultat m√†j statut (drafting) pour {sid}: {update_result}")
            if 'Erreur' in update_result:
                return {**state, 'error_message': f"Erreur M√†J statut (drafting): {update_result}"}
            try:
                current_plan = memory_manager.load_report_plan()
                title = get_title_from_plan(current_plan, sid)
                if not title: return {**state, 'error_message': f"Titre non trouv√© ID {sid}."}
                guidelines = config.STRUCTURED_GUIDELINES.get(title, [])
                log.info(f"Section: '{title}' (ID: {sid}). Guidelines: {len(guidelines)}")
                return {**state, 'current_section_title': title, 'structured_guidelines': guidelines}
            except Exception as e_plan:
                 log.error(f"Erreur chargement plan: {e_plan}", exc_info=True)
                 return {**state, 'error_message': f"Erreur lecture plan: {e_plan}"}

        def gather_focused_context(state: ReportWorkflowState) -> ReportWorkflowState:
            # (Logique inchang√©e par rapport √† la version pr√©c√©dente)
            title = state['current_section_title']
            guidelines = state['structured_guidelines']
            if not title: return {**state, 'error_message': 'Titre manquant (gather_context).'}
            query = f"Extraits de journaux pertinents pour la section '{title}'. Chercher exemples, faits, r√©alisations, r√©flexions li√©s √† : {'; '.join(guidelines)}. Contexte global : {state.get('objective', '')}"
            log.info(f"Lancement recherche RAG pour '{title}'...")
            try:
                docs = vector_db_manager.search_journals(query=query, k=config.RAG_NUM_RESULTS)
                if docs:
                    context_text = f"Contexte pertinent trouv√© pour '{title}':\n\n" + "\n\n---\n\n".join([f"Source (Date approx.): {d.get('metadata', {}).get('date', 'Inconnue')}\nExtrait: {d.get('document', '')}" for d in docs])
                    log.info(f"{len(docs)} extraits RAG trouv√©s.")
                else:
                    context_text = f"Aucun exemple sp√©cifique trouv√© pour '{title}'."
                    log.warning(f"Aucun r√©sultat RAG pour '{title}'.")
                return {**state, 'journal_context': context_text}
            except Exception as e_rag:
                log.error(f"Erreur RAG: {e_rag}", exc_info=True)
                return {**state, 'error_message': f"Erreur RAG: {e_rag}"}

        # --- Nouveau n≈ìud : Filtrage du contexte RAG ---
        def filter_rag_context(state: ReportWorkflowState) -> ReportWorkflowState:
            title = state['current_section_title']
            guidelines = state['structured_guidelines']
            context = state['journal_context']
            log.info(f"Filtrage/√âvaluation du contexte RAG pour la section '{title}'...")

            if not context or "Aucun exemple sp√©cifique trouv√©" in context:
                 log.warning(f"Pas de contexte RAG √† filtrer pour '{title}'. Marqu√© comme non pertinent.")
                 return {**state, 'is_context_relevant': False} # Ou True si on accepte de continuer sans contexte? False semble plus s√ªr.

            prompt_template = ChatPromptTemplate.from_messages([
                ("system", "Tu es un assistant IA √©valuant la pertinence d'un contexte pour r√©diger une section de rapport d'alternance. R√©ponds uniquement par 'Oui' ou 'Non', suivi d'une br√®ve justification (1 phrase max)."),
                ("human", """√âvalue si le CONTEXTE suivant est r√©ellement utile et pertinent pour r√©diger la section de rapport '{section_title}' en suivant les GUIDELINES.

GUIDELINES:
- {guidelines}

CONTEXTE √Ä √âVALUER:
---
{context}
---

Ce contexte contient-il des informations concr√®tes, exemples, faits ou r√©flexions qui aident *directement* √† traiter les guidelines pour cette section sp√©cifique ?

R√©ponse (Oui/Non + Justification br√®ve):""")
            ])
            chain = prompt_template | llm_analysis | StrOutputParser()
            try:
                response = chain.invoke({
                    "section_title": title,
                    "guidelines": "; ".join(guidelines) if guidelines else "Objectif g√©n√©ral de la section",
                    "context": context
                })
                log.info(f"R√©sultat √©valuation pertinence contexte: {response}")
                is_relevant = response.lower().strip().startswith('oui')
                return {**state, 'is_context_relevant': is_relevant}
            except Exception as e_filter:
                 log.error(f"Erreur lors de l'√©valuation du contexte RAG: {e_filter}", exc_info=True)
                 # En cas d'erreur, on consid√®re le contexte comme non pertinent par d√©faut? Ou on continue?
                 return {**state, 'is_context_relevant': False, 'error_message': f"Erreur filtre RAG: {e_filter}"}


        def structure_section_content(state: ReportWorkflowState) -> ReportWorkflowState:
            title = state['current_section_title']
            guidelines = state['structured_guidelines']
            context = state['journal_context'] if state.get('is_context_relevant') else "Aucun contexte pertinent fourni par le RAG."
            log.info(f"Structuration du contenu pour la section: {title}")

            holistic_summary = json.dumps(holistic_analysis_content, indent=2, ensure_ascii=False) if holistic_analysis_content else "Analyse holistique non disponible."

            prompt_template = ChatPromptTemplate.from_messages([
                ("system", "Tu es un architecte de contenu expert en m√©moires Epitech. Ton r√¥le est de cr√©er un plan structur√© et d√©taill√© (en Markdown) pour une section de rapport, bas√© sur les guidelines, le contexte RAG fourni et l'analyse holistique globale."),
                ("human", """Cr√©e un plan d√©taill√© en Markdown pour la section de rapport intitul√©e '{section_title}'.

Objectif global de la section (Guidelines):
- {guidelines}

Contexte extrait des journaux de bord (RAG - √† utiliser si pertinent):
---
{rag_context}
---

Analyse holistique globale du parcours de l'√©tudiant (pour le contexte g√©n√©ral):
---
{holistic_analysis}
---

**Instructions:**
1.  **Structure Markdown:** Utilise des titres (##, ###), des listes √† puces (-) et des sous-points pour organiser le plan.
2.  **Couverture des Guidelines:** Assure-toi que chaque point des guidelines est adress√© dans le plan.
3.  **Int√©gration Contexte:** Sugg√®re o√π int√©grer les exemples concrets du contexte RAG (s'il est pertinent) ou de l'analyse holistique. Mentionne explicitement [Exemple RAG: ...] ou [Ref Holistique: ...] l√† o√π c'est appropri√©.
4.  **Logique et Coh√©rence:** Le plan doit pr√©senter une structure logique et fluide pour la future r√©daction.
5.  **Contenu Minimal:** M√™me sans contexte RAG pertinent, propose une structure bas√©e sur les guidelines et l'analyse holistique.
6.  **Sortie:** Ne retourne QUE le plan en Markdown.

Plan D√©taill√© en Markdown:""")
            ])
            chain = prompt_template | llm_analysis | StrOutputParser()

            try:
                structured_plan = chain.invoke({
                    "section_title": title,
                    "guidelines": "; ".join(guidelines) if guidelines else "Objectif g√©n√©ral de la section",
                    "rag_context": context,
                    "holistic_analysis": holistic_summary[:2000] # Tronquer si trop long
                })
                log.info(f"Plan structur√© g√©n√©r√© pour '{title}'.")
                return {**state, 'analysis_result': structured_plan}
            except Exception as e_struct:
                log.error(f"Erreur lors de la structuration du contenu: {e_struct}", exc_info=True)
                return {**state, 'error_message': f"Erreur structuration: {e_struct}"}


        def write_section_prose(state: ReportWorkflowState) -> ReportWorkflowState:
            title = state['current_section_title']
            structured_plan = state['analysis_result']
            feedback = state.get('prose_feedback') # R√©cup√®re le feedback de l'it√©ration pr√©c√©dente
            attempt = state.get('writing_attempts', 0) + 1
            log.info(f"R√©daction de la prose pour '{title}' (Tentative {attempt})...")

            if not structured_plan:
                log.error(f"Plan structur√© manquant pour la r√©daction de '{title}'.")
                return {**state, 'error_message': f"Plan manquant (write {title})."}

            prompt_list = [
                ("system", f"Tu es un r√©dacteur acad√©mique expert, sp√©cialis√© dans les rapports d'alternance Epitech (Mission Professionnelle Digi5). R√©dige la section demand√©e en suivant strictement le plan fourni. Adopte un style formel, neutre, objectif (bas√© sur les faits implicites dans le plan) et respecte l'anonymisation (utilise les r√¥les g√©n√©riques si mentionn√©s). R√©dige directement le contenu de la section, sans introduction ou conclusion superflue sur ton r√¥le."),
                ("human", """R√©dige le contenu de la section de rapport intitul√©e '{section_title}' en te basant *uniquement* sur le plan d√©taill√© ci-dessous.

**Plan √† suivre:**
---
{structured_plan}
---
""" + (f"\n**Feedback de la tentative pr√©c√©dente (√† prendre en compte pour am√©liorer):**\n{feedback}\n" if feedback else "") + """
**Instructions de R√©daction:**
1.  **Suivre le Plan:** Adresse chaque point du plan dans l'ordre.
2.  **Style Acad√©mique:** Formel, pr√©cis, phrases compl√®tes. Utilise le vouvoiement implicite ou un ton neutre.
3.  **Neutralit√© & Objectivit√©:** Base-toi sur les √©l√©ments du plan (qui d√©rivent du contexte). √âvite les opinions personnelles non justifi√©es.
4.  **Anonymisation:** Respecte l'anonymisation mentionn√©e (ex: 'le Manager').
5.  **Coh√©rence:** Assure une transition fluide entre les points.
6.  **Contenu Complet:** R√©dige un texte suffisamment d√©velopp√© pour couvrir le plan.
7.  **Sortie:** Ne retourne QUE le texte r√©dig√© de la section.

Contenu R√©-√©crit de la Section (si feedback) / Contenu de la Section:""")
            ]
            prompt_template = ChatPromptTemplate.from_messages(prompt_list)
            chain = prompt_template | llm_writing | StrOutputParser()

            try:
                written_text = chain.invoke({
                    "section_title": title,
                    "structured_plan": structured_plan,
                    "feedback": feedback or "N/A"
                })
                log.info(f"Prose r√©dig√©e pour '{title}'.")
                # R√©initialise le feedback apr√®s une tentative r√©ussie
                return {**state, 'written_content': written_text, 'writing_attempts': attempt, 'prose_feedback': None}
            except Exception as e_write:
                 log.error(f"Erreur lors de la r√©daction de la prose: {e_write}", exc_info=True)
                 return {**state, 'error_message': f"Erreur r√©daction: {e_write}", 'writing_attempts': attempt}

        # --- Nouveau n≈ìud : √âvaluation de la prose ---
        def evaluate_written_prose(state: ReportWorkflowState) -> ReportWorkflowState:
            title = state['current_section_title']
            plan = state['analysis_result']
            prose = state['written_content']
            log.info(f"√âvaluation de la prose r√©dig√©e pour la section '{title}'...")

            if not prose:
                log.error(f"Pas de prose √† √©valuer pour '{title}'.")
                return {**state, 'is_prose_adequate': False, 'prose_feedback': "Le contenu r√©dig√© est vide."}

            prompt_template = ChatPromptTemplate.from_messages([
                ("system", "Tu es un √©valuateur qualit√© pour rapport d'alternance Epitech. √âvalue la prose fournie selon les crit√®res sp√©cifi√©s. R√©ponds uniquement par 'Oui' si ad√©quat, ou 'Non' suivi d'un feedback *constructif et concis* (2-3 points max) si des am√©liorations sont n√©cessaires."),
                ("human", """√âvalue si la PROSE suivante est une r√©daction ad√©quate pour la section '{section_title}', en se basant sur le PLAN fourni.

Crit√®res d'√©valuation:
1.  **Ad√©quation au Plan:** La prose suit-elle fid√®lement la structure et les points du plan ?
2.  **Style Acad√©mique:** Le style est-il formel, neutre et objectif ?
3.  **Clart√© et Coh√©rence:** Le texte est-il facile √† comprendre et logiquement structur√© ?
4.  **Anonymisation:** L'anonymisation semble-t-elle respect√©e (pas de noms propres √©vidents)?

PLAN DE LA SECTION:
---
{section_plan}
---

PROSE √Ä √âVALUER:
---
{written_prose}
---

La prose est-elle ad√©quate selon ces crit√®res ?

R√©ponse (Oui / Non + Feedback constructif si Non):""")
            ])
            chain = prompt_template | llm_analysis | StrOutputParser()

            try:
                response = chain.invoke({
                    "section_title": title,
                    "section_plan": plan,
                    "written_prose": prose
                })
                log.info(f"R√©sultat √©valuation prose: {response}")
                is_adequate = response.lower().strip().startswith('oui')
                feedback = None if is_adequate else response.partition('\n')[2].strip() or response.partition(' ')[2].strip() # Extrait le feedback apr√®s Oui/Non

                return {**state, 'is_prose_adequate': is_adequate, 'prose_feedback': feedback}
            except Exception as e_eval:
                log.error(f"Erreur lors de l'√©valuation de la prose: {e_eval}", exc_info=True)
                # En cas d'erreur, on consid√®re la prose comme non ad√©quate par d√©faut
                return {**state, 'is_prose_adequate': False, 'prose_feedback': f"Erreur lors de l'√©valuation: {e_eval}", 'error_message': f"Erreur √©val prose: {e_eval}"}


        def apply_guardrails_and_save(state: ReportWorkflowState) -> ReportWorkflowState:
            # (Logique interne de garde-fous et sauvegarde inchang√©e)
            sid = state['current_section_id']
            written_content = state.get('written_content')
            title = state.get('current_section_title', 'Section inconnue')
            if not sid: return {**state, 'error_message': 'ID section manquant (save).'}
            if not written_content:
                 log.warning(f"Contenu √©crit manquant pour {sid}. Mise √† jour statut en pending.")
                 update_status.invoke({'tool_input': f"{sid},pending"})
                 return {**state, 'error_message': f"Contenu vide pour {sid}"}

            log.info(f"Application garde-fous et sauvegarde pour: {title} (ID: {sid})")
            final_content = written_content
            try:
                mapping = config.ANONYMIZATION_MAPPING
                nb_replacements = 0
                for original, replacement in mapping.items():
                    final_content, count = re.subn(r'\b' + re.escape(original) + r'\b', replacement, final_content, flags=re.IGNORECASE)
                    if count > 0: log.info(f"Anonymisation: '{original}' -> '{replacement}' ({count} fois).")
                    nb_replacements += count
                log.info(f"Anonymisation termin√©e ({nb_replacements} rempl.) pour '{title}'.")
            except Exception as e_guard:
                 log.error(f"Erreur garde-fous pour {sid}: {e_guard}", exc_info=True)
                 final_content = written_content # Fallback

            status_to_save = 'drafted'
            try:
                memory_manager.update_section_content(sid, final_content, status_to_save)
                log.info(f"Contenu final et statut '{status_to_save}' sauvegard√©s pour {sid}.")
            except Exception as e_save:
                log.error(f"Erreur sauvegarde plan pour {sid}: {e_save}", exc_info=True)
                status_to_save = 'failed'
                update_status.invoke({'tool_input': f"{sid},{status_to_save}"})
                return {**state, 'error_message': f"Erreur sauvegarde plan ({sid}): {e_save}"}

            # R√©initialisation pour la prochaine it√©ration
            return {
                **state,
                'current_section_id': None, 'current_section_title': None, 'structured_guidelines': [],
                'journal_context': None, 'is_context_relevant': None, 'analysis_result': None,
                'written_content': None, 'is_prose_adequate': None, 'prose_feedback': None,
                'final_content': final_content, # Garde le contenu de la derni√®re section
                'error_message': None, 'writing_attempts': 0,
            }

        # --- Logique de d√©cision (Mise √† jour pour int√©grer les nouvelles √©tapes) ---
        def decide_next_step(state: ReportWorkflowState) -> str:
            log.debug(f"D√©cision bas√©e sur l'√©tat: ID={state.get('current_section_id')}, Iter={state.get('iterations')}, Err={state.get('error_message')}, Pending={state.get('pending_check_result')}")
            if state.get('error_message'):
                log.error(f"Erreur d√©tect√©e: {state['error_message']}. Fin.")
                return END
            if state.get('iterations', 0) > args.max_iterations: # > car check_pending incr√©mente avant d√©cision
                log.warning(f"Limite d'it√©rations ({args.max_iterations}) atteinte. Arr√™t.")
                return END

            pending_result = state.get('pending_check_result', '')
            if 'COMPLETED' in pending_result:
                log.info("Toutes sections trait√©es. Fin.")
                return END

            # Si on vient de check_pending et qu'il y a une section √† traiter
            if state.get('current_section_id') and state.get('current_section_title') is None:
                 log.info(f"Section {state['current_section_id']} trouv√©e -> 'prepare_drafting'")
                 return 'prepare_drafting'

            # Si on a pr√©par√©, on r√©cup√®re le contexte
            if state.get('current_section_title') and state.get('journal_context') is None:
                 log.info("Pr√©paration OK -> 'gather_focused_context'")
                 return 'gather_focused_context'

            # Si on a le contexte, on le filtre
            if state.get('journal_context') and state.get('is_context_relevant') is None:
                 log.info("Contexte RAG r√©cup√©r√© -> 'filter_rag_context'")
                 return 'filter_rag_context'

            # Si le contexte est filtr√© (pertinent ou non), on structure
            if state.get('is_context_relevant') is not None and state.get('analysis_result') is None:
                 log.info(f"Contexte RAG filtr√© (Pertinent: {state['is_context_relevant']}) -> 'structure_section_content'")
                 return 'structure_section_content'

            # Si on a structur√©, on √©crit la prose
            if state.get('analysis_result') and state.get('written_content') is None:
                 log.info("Structuration OK -> 'write_section_prose'")
                 return 'write_section_prose'

            # Si on a √©crit la prose, on l'√©value
            if state.get('written_content') and state.get('is_prose_adequate') is None:
                 log.info("Prose √©crite -> 'evaluate_written_prose'")
                 return 'evaluate_written_prose'

            # Si l'√©valuation de la prose est termin√©e
            if state.get('is_prose_adequate') is not None:
                 if state['is_prose_adequate']:
                     log.info("Prose jug√©e ad√©quate -> 'apply_guardrails_and_save'")
                     return 'apply_guardrails_and_save'
                 else:
                     # Boucle de correction pour l'√©criture
                     max_attempts = args.max_writing_attempts
                     if state['writing_attempts'] < max_attempts:
                         log.warning(f"Prose jug√©e inad√©quate (Tentative {state['writing_attempts']}/{max_attempts}). Retour √† 'write_section_prose' avec feedback.")
                         # R√©initialise seulement 'written_content' et 'is_prose_adequate' pour retenter
                         state['written_content'] = None
                         state['is_prose_adequate'] = None
                         # Le feedback est d√©j√† dans l'√©tat
                         return 'write_section_prose' # Retourne directement au n≈ìud d'√©criture
                     else:
                         log.error(f"√âchec de la r√©daction apr√®s {max_attempts} tentatives pour '{state['current_section_title']}'. Sauvegarde avec statut 'failed'.")
                         # Marquer comme √©chou√© et sauvegarder quand m√™me? Ou juste arr√™ter?
                         # Pour l'instant, on sauvegarde en failed.
                         state['error_message'] = f"Echec √©criture apr√®s {max_attempts} tentatives."
                         # On force le passage √† la sauvegarde qui mettra le statut 'failed' (ou g√©rera l'erreur)
                         return 'apply_guardrails_and_save' # Ou END ? Sauvegarder permet de voir le dernier essai.

            # Si on a sauvegard√©, on retourne v√©rifier les sections restantes
            if state.get('final_content') is not None: # final_content est mis √† jour par apply_guardrails_and_save
                 log.info("Sauvegarde OK -> 'check_pending'")
                 # Attention : final_content reste dans l'√©tat, mais check_pending le r√©initialise
                 return 'check_pending'


            # Cas d'erreur ou √©tat inattendu
            log.error("√âtat inattendu dans decide_next_step. Arr√™t.")
            return END


        # --- Construction et ex√©cution du graphe (Mise √† jour) ---
        workflow = StateGraph(ReportWorkflowState)

        # Ajout des n≈ìuds
        workflow.add_node("check_pending", check_pending)
        workflow.add_node("prepare_drafting", prepare_drafting)
        workflow.add_node("gather_focused_context", gather_focused_context)
        workflow.add_node("filter_rag_context", filter_rag_context) # Nouveau
        workflow.add_node("structure_section_content", structure_section_content)
        workflow.add_node("write_section_prose", write_section_prose)
        workflow.add_node("evaluate_written_prose", evaluate_written_prose) # Nouveau
        workflow.add_node("apply_guardrails_and_save", apply_guardrails_and_save)

        # Point d'entr√©e
        workflow.set_entry_point("check_pending")

        # Ajout des ar√™tes (Transitions)
        # Utilisation de la fonction decide_next_step pour simplifier
        workflow.add_conditional_edges(
            "check_pending",
            lambda x: decide_next_step(x), # Utilise la fonction de d√©cision
             {
                "prepare_drafting": "prepare_drafting",
                END: END
            }
        )
        workflow.add_conditional_edges(
             "prepare_drafting",
             lambda x: decide_next_step(x),
             {
                 "gather_focused_context": "gather_focused_context",
                 END: END # Si erreur dans prepare_drafting
             }
        )
        workflow.add_conditional_edges(
             "gather_focused_context",
             lambda x: decide_next_step(x),
              {
                 "filter_rag_context": "filter_rag_context",
                 END: END # Si erreur dans gather_focused_context
             }
        )
        workflow.add_conditional_edges(
             "filter_rag_context",
             lambda x: decide_next_step(x),
              {
                 "structure_section_content": "structure_section_content",
                 END: END # Si erreur dans filter_rag_context
             }
        )
        workflow.add_conditional_edges(
             "structure_section_content",
             lambda x: decide_next_step(x),
              {
                 "write_section_prose": "write_section_prose",
                 END: END # Si erreur dans structure_section_content
             }
        )
         # La d√©cision apr√®s write_section_prose m√®ne √† evaluate_written_prose
        workflow.add_conditional_edges(
             "write_section_prose",
             lambda x: decide_next_step(x),
              {
                 "evaluate_written_prose": "evaluate_written_prose",
                 END: END # Si erreur dans write_section_prose
             }
        )
         # La d√©cision apr√®s evaluate_written_prose est cl√© pour la boucle de correction
        workflow.add_conditional_edges(
             "evaluate_written_prose",
             decide_next_step, # decide_next_step g√®re la logique Oui/Non/Max Attempts
             {
                 "apply_guardrails_and_save": "apply_guardrails_and_save", # Si Oui ou Max Attempts atteint
                 "write_section_prose": "write_section_prose", # Si Non et tentatives restantes
                 END: END # Si erreur dans evaluate_written_prose
             }
        )
        # Apr√®s sauvegarde, on retourne toujours √† check_pending (g√©r√© par decide_next_step)
        workflow.add_conditional_edges(
             "apply_guardrails_and_save",
             lambda x: decide_next_step(x),
             {
                 "check_pending": "check_pending",
                 END: END # Si erreur pendant la sauvegarde
             }
        )


        # Compilation
        app = workflow.compile()
        log.info("Graphe LangGraph avec r√©flexion compil√©.")

        # Ex√©cution
        print("\n--- D√©marrage ex√©cution workflow avec r√©flexion ---")
        initial_state: ReportWorkflowState = {
            'objective': args.objective, 'current_section_id': None, 'current_section_title': None,
            'structured_guidelines': [], 'journal_context': None, 'is_context_relevant': None,
            'analysis_result': None, 'written_content': None, 'is_prose_adequate': None,
            'prose_feedback': None, 'final_content': None, 'pending_check_result': '',
            'iterations': 0, 'writing_attempts': 0, 'error_message': None,
        }
        recursion_limit = args.max_iterations * 15 + 30 # Augment√© pour les boucles potentielles
        log.info(f"Limite r√©cursion: {recursion_limit}")

        try:
            final_state = app.invoke(initial_state, config={"recursion_limit": recursion_limit})
            print("\n--- Ex√©cution workflow termin√©e ---")
            log.info(f"√âtat final: {final_state}")
            # Affichage r√©sultat (inchang√©)
            if final_state.get('error_message'): print(f"\nSORTIE: Erreur: {final_state['error_message']}")
            elif final_state.get('pending_check_result') and 'COMPLETED' in final_state['pending_check_result']:
                print(f"\nSORTIE: Workflow termin√©. Plan mis √† jour: {args.plan_file}")
                print("Lancer 'assemble_report' pour g√©n√©rer le DOCX.")
            elif final_state.get('iterations', 0) > args.max_iterations: print(f"\nSORTIE: Limite {args.max_iterations} it√©rations atteinte.")
            else: print("\nSORTIE: Arr√™t inattendu.")

        except Exception as e_invoke:
             log.critical(f"Erreur fatale invocation graphe: {e_invoke}", exc_info=True)
             sys.exit(1)

    else:
        log.error(f"Commande inconnue: {args.command}")
        parser.print_help()
        sys.exit(1)

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\nOp√©ration interrompue.")
        log.info("Interruption par utilisateur.")
        sys.exit(130)
    except SystemExit as e:
         if e.code != 0: log.warning(f"Sortie programme avec code: {e.code}")
         else: log.info("Sortie normale.")
         sys.exit(e.code)
    except Exception as e:
        log.critical(f"Erreur fatale non intercept√©e: {e}", exc_info=True)
        print(f"\nERREUR FATALE: {e}")
        sys.exit(1)