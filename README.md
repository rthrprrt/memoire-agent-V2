# Apprenticeship Report Agent (memoire-agent-V2)

This AI agent aims to automate the creation of an MSc Apprenticeship Report ("Mission Professionnelle Digi5") using daily journal entries (DOCX) and official guidelines (PDF). It leverages local embeddings for context retrieval and a configurable LLM (Google Gemini API via LangChain or a local Ollama model) for reasoning, task execution, and content generation.

## Current Status & Features (Checkpoint: LangGraph Implemented - Holistic Analysis Failing)

*   âœ… **DOCX/PDF Processing:** Parses journals (YYYY-MM-DD.docx format) and guidelines PDF.
*   âœ… **Local Embeddings:** Uses local Sentence Transformers (`paraphrase-multilingual-mpnet-base-v2`) via ChromaDB. Data remains local during vectorization.
*   âœ… **Vector Storage:** Separate ChromaDB collections (`journal_entries`, `reference_docs`) persisted locally (`vector_db/`).
*   âœ… **Configurable LLM:** Supports **Google Gemini API** and **local Ollama models** (via `langchain-community`). Choice via `config.py` or `--llm` argument. (`llm_interface.py`). Currently testing with Ollama (`llama3.1:8b-instruct-q8_0`).
*   âœ… **Report Planning:** Command `create_plan` generates `output/report_plan.json` with unique section IDs and status tracking (`report_planner.py`, `memory_manager.py`).
*   âœ… **LangGraph Workflow (`run_agent`):** Agent logic refactored using **LangGraph** for explicit state management and control flow. The graph implements a **2-step writing process** (Analyze/Structure -> Write Prose) per section.
*   âœ… **Core Tools:** Base tools for getting pending sections and updating status (`GetPendingSectionsTool`, `UpdateSectionStatusTool`) are functional within the graph. Vector search tools are used internally by graph nodes.
*   âœ… **Guardrails (Basic):** Post-processing node includes Python code for basic anonymization enforcement.
*   âœ… **Report Assembly:** Command `assemble_report` generates DOCX from the completed plan JSON.
*   ðŸ”´ **BLOCKING ISSUE:** The **`analyze_journals` command FAILS** to produce reliable, clean JSON output. The Ollama LLM (`llama3.1:8b-instruct-q8_0`), despite a detailed prompt requesting strict JSON format between delimiters, often includes conversational text, causing `json.loads()` to fail. Robust extraction logic (regex between delimiters) was added but also failed in the last test, likely because the LLM didn't use the delimiters correctly or the JSON itself was malformed. The raw LLM output is saved to `output/holistic_analysis_raw.txt`.
*   âš ï¸ **Untested Workflow:** Due to the failure of `analyze_journals`, the main `run_agent` workflow (which depends on the holistic analysis JSON) has not been successfully tested with the new 2-step writing logic.
*   âš ï¸ **Content Quality (Anticipated):** Previous tests with simpler prompts showed mediocre content quality from the local LLM. Significant improvements are needed via better analysis, prompting, and potentially critique loops.

```mermaid
graph TD
    subgraph CLI
        A[main.py] -->|Commands| B[Agent Core]
    end
    
    subgraph "Agent Core"
        B -->|Orchestration| C[LangGraph]
        C -->|State| D[Memory Manager]
        C -->|Tools| E[Agent Tools]
        
        C -->|LLM Requests| F[LLM Service]
        F -->|API Calls| G[Ollama/Gemini]
        
        C -->|Processing| H[Document Processor]
        H -->|Text Extract| I[DOCX/PDF Extract]
        I -->|Analysis| J[Content Analysis]
        J -->|Tags/Data| D
        
        C -->|Search| D
        D -->|Vector Search| K[ChromaDB]
        
        C -->|Generate| L[Report Generator]
        L -->|Assembly| M[DOCX Output]
    end
    
    subgraph "Data Storage"
        K -->|Collections| N[Journal Vectors]
        K -->|Collections| O[Reference Vectors]
        D -->|JSON| P[Plan Files]
        D -->|Config| Q[Settings]
    end
    
    subgraph "External Services"
        G -->|Models| R[Local Ollama]
        G -->|API| S[Google Gemini]
        K -->|Embeddings| T[Sentence Transformers]
    end
    
    M -->|Output| U[Final Reports]
    P -->|Backup| V[Progress Tracking]
```

## Structure dÃ©taillÃ©e 
```
memoire-agent/
â”œâ”€â”€ backend/                     # Non implÃ©mentÃ© (structure future)
â”‚   â”œâ”€â”€ api/                     # DÃ©finitions API FastAPI (futur)
â”‚   â”‚   â”œâ”€â”€ dependencies.py      # DÃ©pendances FastAPI
â”‚   â”‚   â”œâ”€â”€ hallucination.py     # Fonctions pour la dÃ©tection d'hallucinations
â”‚   â”‚   â””â”€â”€ models/              # ModÃ¨les Pydantic pour API
â”‚   â”‚       â”œâ”€â”€ admin.py         # ModÃ¨les admin et maintenance
â”‚   â”‚       â”œâ”€â”€ ai.py            # ModÃ¨les pour l'IA et gÃ©nÃ©ration
â”‚   â”‚       â”œâ”€â”€ base.py          # ModÃ¨les de base partagÃ©s
â”‚   â”‚       â”œâ”€â”€ export.py        # ModÃ¨les d'exportation
â”‚   â”‚       â”œâ”€â”€ hallucination.py # ModÃ¨les dÃ©tection d'hallucinations
â”‚   â”‚       â”œâ”€â”€ journal.py       # ModÃ¨les pour journal de bord
â”‚   â”‚       â””â”€â”€ memoire.py       # ModÃ¨les pour sections du mÃ©moire
â”‚   â”œâ”€â”€ routes/                  # Endpoints API
â”‚   â”‚   â”œâ”€â”€ admin.py             # Routes administratives
â”‚   â”‚   â”œâ”€â”€ ai.py                # Routes IA et gÃ©nÃ©ration
â”‚   â”‚   â”œâ”€â”€ export.py            # Routes d'exportation
â”‚   â”‚   â”œâ”€â”€ hallucination.py     # Routes dÃ©tection d'hallucinations
â”‚   â”‚   â”œâ”€â”€ journal.py           # Routes pour journal de bord
â”‚   â”‚   â”œâ”€â”€ memoire.py           # Routes pour le mÃ©moire
â”‚   â”‚   â””â”€â”€ search.py            # Routes de recherche
â”‚   â””â”€â”€ utils/                   # Utilitaires API
â”‚       â””â”€â”€ text_analysis.py     # Analyse des textes API
â”‚
â”œâ”€â”€ core/                        # Composants centraux
â”‚   â”œâ”€â”€ config.py                # Configuration application
â”‚   â”œâ”€â”€ dummy_vectordb.py        # Fallback ChromaDB
â”‚   â”œâ”€â”€ exceptions.py            # Exceptions personnalisÃ©es
â”‚   â”œâ”€â”€ logging.py               # Configuration logs centrale
â”‚   â”œâ”€â”€ logging_config.py        # Configuration logs avancÃ©e
â”‚   â””â”€â”€ memory_manager.py        # Gestion de la mÃ©moire vectorielle
â”‚
â”œâ”€â”€ data/                        # DonnÃ©es persistantes
â”‚   â”œâ”€â”€ memoire.db               # Base de donnÃ©es SQLite
â”‚   â””â”€â”€ vectordb/                # DonnÃ©es vectorielles (ChromaDB)
â”‚
â”œâ”€â”€ db/                          # Couche d'accÃ¨s aux donnÃ©es
â”‚   â”œâ”€â”€ database.py              # Gestionnaire de connexion BD
â”‚   â”œâ”€â”€ models/                  # ModÃ¨les de donnÃ©es
â”‚   â”‚   â””â”€â”€ db_models.py         # DÃ©finitions des modÃ¨les SQL
â”‚   â””â”€â”€ repositories/            # Repositories (pattern DAO)
â”‚       â”œâ”€â”€ guidelines_repository.py    # Repository pour consignes
â”‚       â”œâ”€â”€ journal_repository.py       # Repository pour journal
â”‚       â””â”€â”€ memoire_repository.py       # Repository pour mÃ©moire
â”‚
â”œâ”€â”€ journals/                    # Dossier des journaux DOCX (entrÃ©e utilisateur)
â”‚   â””â”€â”€ [YYYY-MM-DD.docx]        # Fichiers journaux au format date
â”‚
â”œâ”€â”€ output/                      # Fichiers de sortie gÃ©nÃ©rÃ©s
â”‚   â”œâ”€â”€ holistic_analysis.json   # Analyse holistique des journaux
â”‚   â”œâ”€â”€ holistic_analysis_raw.txt # Sortie brute LLM (debug)
â”‚   â”œâ”€â”€ report_plan.json         # Plan structurÃ© du rapport
â”‚   â””â”€â”€ apprenticeship_report.docx # Rapport final gÃ©nÃ©rÃ©
â”‚
â”œâ”€â”€ logs/                        # Journaux application backend
â”‚
â”œâ”€â”€ schemas/                     # SchÃ©mas JSON pour communication
â”‚   â”œâ”€â”€ action_confirmation_request_schema.json
â”‚   â”œâ”€â”€ action_confirmation_response_schema.json
â”‚   â”œâ”€â”€ data_analysis_request_schema.json
â”‚   â”œâ”€â”€ data_analysis_response_schema.json
â”‚   â”œâ”€â”€ report_generation_request_schema.json
â”‚   â”œâ”€â”€ report_generation_response_schema.json
â”‚   â”œâ”€â”€ report_plan_change_notification_schema.json
â”‚   â”œâ”€â”€ report_plan_retrieval_request_schema.json
â”‚   â”œâ”€â”€ report_plan_retrieval_response_schema.json
â”‚   â”œâ”€â”€ report_plan_update_confirmation_schema.json
â”‚   â”œâ”€â”€ report_plan_update_request_schema.json
â”‚   â”œâ”€â”€ task_assignment_schema.json
â”‚   â”œâ”€â”€ task_completion_notification_schema.json
â”‚   â”œâ”€â”€ user_input_request_schema.json
â”‚   â””â”€â”€ user_input_response_schema.json
â”‚
â”œâ”€â”€ services/                    # Services mÃ©tier (futur backend)
â”‚
â”œâ”€â”€ scripts/                     # Scripts utilitaires
â”‚   â”œâ”€â”€ init.sh                  # Initialisation environnement
â”‚   â””â”€â”€ run_tests.sh             # ExÃ©cution des tests
â”‚
â”œâ”€â”€ vector_db/                   # Base de donnÃ©es vectorielle (ChromaDB)
â”‚   â”œâ”€â”€ [journal_entries]/       # Collection des journaux vectorisÃ©s
â”‚   â””â”€â”€ [reference_docs]/        # Collection des documents de rÃ©fÃ©rence
â”‚
â”œâ”€â”€ .github/workflows/           # CI/CD Pipeline
â”‚   â””â”€â”€ main.yml                 # Workflow GitHub Actions
â”‚
â”œâ”€â”€ .gitignore                   # Fichiers ignorÃ©s par Git
â”œâ”€â”€ LICENSE                      # Licence MIT
â”œâ”€â”€ README.md                    # Documentation principale
â”œâ”€â”€ requirements.txt             # DÃ©pendances Python
â”‚
# === MODULES PYTHON PRINCIPAUX ===
â”œâ”€â”€ main.py                      # Point d'entrÃ©e principal - CLI & LangGraph workflow
â”œâ”€â”€ agent_tools.py               # Outils pour l'agent LangGraph
â”œâ”€â”€ competency_mapper.py         # Mapping des compÃ©tences (LLM)
â”œâ”€â”€ content_analyzer.py          # Analyse de contenu (LLM)
â”œâ”€â”€ data_models.py               # ModÃ¨les Pydantic (JournalEntry, ReportPlan, etc.)
â”œâ”€â”€ document_processor.py        # Traitement DOCX/PDF
â”œâ”€â”€ llm_interface.py             # Interface unifiÃ©e LLM (Ollama/Google)
â”œâ”€â”€ memory_manager.py            # Gestionnaire d'Ã©tat et persistance JSON
â”œâ”€â”€ progress_tracker.py          # Suivi de progression du rapport
â”œâ”€â”€ quality_checker.py           # VÃ©rification qualitÃ© (LLM)
â”œâ”€â”€ reference_manager.py         # Gestion bibliographie Harvard
â”œâ”€â”€ rename_journals.py           # Script de renommage des journaux
â”œâ”€â”€ report_generator.py          # GÃ©nÃ©ration rapport final + assemblage
â”œâ”€â”€ report_planner.py            # CrÃ©ation plan de rapport structurÃ©
â”œâ”€â”€ tag_generator.py             # GÃ©nÃ©ration de tags (LLM)
â”œâ”€â”€ vector_database.py           # Gestionnaire ChromaDB avec embeddings locaux
â””â”€â”€ visualization.py             # Visualisations matplotlib
```

## Revised Roadmap: Stabilize Analysis, Enhance Quality, Implement Control
**Goal:** Achieve reliable autonomous report generation using a local LLM, produce high-quality, personalized, and anonymized content in French, and add advanced features.

**Immediate Priority: Fix Holistic Analysis JSON Generation**
1.  [ ] **Evaluate Raw Analysis Output:** Manually review the content of `output/holistic_analysis_raw.txt`. Is the *information* extracted by the LLM (despite formatting issues) relevant and accurate according to the journals?
2.  [ ] **Implement Robust Parsing/Correction OR Refine Prompt/Model:**
    *   **If Content OK:** Implement robust LangChain parsers (`PydanticOutputParser`, `StructuredOutputParser`) possibly combined with `OutputFixingParser` within the `run_holistic_analysis` function in `main.py` to reliably extract the JSON even from "chatty" LLM output.
    *   **If Content BAD:** Re-design the holistic analysis prompt in `run_holistic_analysis` significantly OR test a different Ollama model (e.g., `mixtral:instruct`) specifically for this JSON extraction task.

**Iteration 2: First End-to-End Test & Quality Baseline** (Requires Fix above)
3.  [ ] **Run Full Workflow (Limited Sections):** Execute `python main.py run_agent --llm ollama --max_iterations 3` after `analyze_journals` is fixed.
4.  [ ] **Assess Baseline Quality:** Evaluate the generated content for the first few sections based on the 2-step process (relevance, analysis depth, anonymization, neutrality, style).
5.  [ ] **Refine Analysis & Writing Prompts:** Iterate on the prompts within the LangGraph nodes (`structure_section_content`, `write_section_prose` in `main.py`) based on the quality assessment.

**Iteration 3: Epitech Alignment, Critique Loop & Control**
6.  [ ] **Focus Epitech Guidelines:** Ensure prompts explicitly use structured guidelines from `config.py`. Align `DEFAULT_REPORT_STRUCTURE`.
7.  [ ] **Implement Critique Loop:** Add a `critique_section` node in LangGraph using an LLM call to evaluate generated sections against guidelines and quality criteria. Add conditional logic to revise or mark as 'failed'.
8.  [ ] **Basic Agent Control:** Implement simple `Go`/`Stop` functionality (likely requires running the LangGraph invoke in a separate thread/process). Add `GetAgentStatusTool`.
9.  [ ] **Setup CI/CD Pipeline (GitHub Actions).**

**Iteration 4 & Beyond: Advanced Features**
10. [ ] **Human-in-the-Loop (HITL):** Add wait points in LangGraph for user validation/correction.
11. [ ] **Web Search Integration.**
12. [ ] **Bibliography Management.**
13. [ ] **Explore GraphRAG** if vector RAG proves insufficient for deep analysis.
14. [ ] **Refine UI/Interaction.**

## Setup (Local Conda Environment)
... (Setup instructions remain largely the same as V3, ensure Ollama + chosen model are installed) ...

## Usage
*   **Analyze Journals (Run First):** `python main.py analyze_journals [--llm ollama/google]`
*   **Create/Reset Plan:** `python main.py create_plan`
*   **Run Agent Workflow:** (Set env vars if needed) `python main.py run_agent --llm ollama [--max_iterations N]`
*   **Assemble Report:** `python main.py assemble_report [--plan_file <path>] [--output_file <path>]`
*   **(Other):** `process_guidelines`, `check_quality`, `create_visuals`, `manage_refs`
